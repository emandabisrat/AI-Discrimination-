# AI-Discrimination-

![D37B2C38-6C57-49D5-A94B-2D2482FDA9F5_4_5005_c](https://github.com/user-attachments/assets/6e1ed2fd-3528-4a46-9b86-c60e8c3bb7c5)

## Background
For this project, our team examined the potential for algorithmic bias in AI-powered resume screening by simulating a diverse applicant pool and testing decisions from GPT-4o. Using a synthetic dataset of resumes with controlled variations in gendered names, education, and experience, we evaluated GPT-4oâ€™s selections for a hypothetical job.

## Report
Our analysis reveals suggestive trends: for instance, qualified female candidates were selected at higher rates than equivalently qualified males, while some less-qualified male candidates were accepted more often than similarly unqualified females. These patterns echo documented cases of bias (e.g., an AI system favoring male applicants) and underscore how AI can inadvertently amplify societal prejudices. We discuss ethical implications, noting that unbiased training data and transparency are crucial. Policy recommendations include routine fairness audits of hiring algorithms, transparency reports, and a certification system to ensure AI tools promote fairness rather than perpetuate existing biases. 
